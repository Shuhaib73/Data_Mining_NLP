# Data Extraction and Natural Language Processing (NLP) Project

## ğŸ“– Project Overview
The goal of this project is to extract textual content from articles available at the provided URLs and perform text analysis to compute several defined metrics, including:

## ğŸš€ Features

- **Sentiment Analysis**: Positive Score, Negative Score, Polarity Score, and Subjectivity Score.
- **Readability Metrics**: Average Sentence Length, Percentage of Complex Words, Fog Index, and Average Number of Words per Sentence.
- **Other Metrics**: Complex Word Count, Word Count, Syllables per Word, Personal Pronouns, and Average Word Length.

The project automates the extraction, cleaning, and analysis of data using Python and outputs the results as an Excel file.

---
## âš™ï¸ Project Workflow

## **Data Extraction**
- To accomplish text extraction, I have used Python's requests and BeautifulSoup library to fetch the HTML content from URLs listed in the input.xlsx file. The HTML content is then parsed using BeautifulSoup with the lxml parser to efficiently extract the article's title and body text, while avoiding unnecessary elements like headers, footers, and ads. The relevant content is saved into individual text files named with the unique URL_ID for each article. This approach ensures that only the necessary article information is extracted and stored for further processing.

---

## **Natural Language Processing and Data Analysis**
- To perform textual analysis on the extracted article texts and compute the specified variables, I used a structured approach encapsulated in the TextPreprocessing class. Below I have mentioned summary of the steps I performed to accomplish:

---	Data Preparation and Cleaning and Analysis:  The â€˜get_stopwords_get_dataâ€™ method combines multiple stopword files into one and reads text files from a specified directory. It then preprocesses these texts by removing stopwords, special characters, punctuation, and digits. This cleaned data is returned in a structured format as a DataFrame.

--- Performs **word tokenization and lemmatization using NLTK** to enhance the quality of text processing.

---	The â€˜preprocess_analyzeâ€™ method performs further text cleaning by tokenizing content into sentences and words, removing stopwords, and ensuring proper formatting. 

--- -	The â€˜get_masterdic_filesâ€™ method extracts and processes positive and negative word dictionaries from a zip file. It decodes the files, removes stopwords, and stores the clean lists of positive and negative words as Instance attributes. I have used a try and except block to handle any potential issues that may arise during the process.

--- -	The â€˜compute_variablesâ€™ method performs several text analysis tasks to compute various readability and sentiment metrics for the extracted data. This is the final method in the process.     

----

## ğŸ› ï¸ Tools and Libraries

- Python 3.11.5
- BeautifulSoup, Request
- Pandas, NumPy, Matplotlib, Seaborn
- NLP - NLTK

---

## ğŸ“‚ **Project Structure**

```
Project/
â”œâ”€â”€ main.py                    # entry point for running the web app.
â”œâ”€â”€ requirements.txt           # File listing all dependencies to set up the environment.
â”œâ”€â”€ README.md                  # Project documentation, including setup, usage, and details.
â”œâ”€â”€ data/                      # Contains datasets used in the project.
â”‚   â”œâ”€â”€ Input.xlsx             # Input data for sentiment analysis.
â”‚   â”œâ”€â”€ output_data_structure.xlsx  # Expected structure of output data.
â”‚   â”œâ”€â”€ StopWords.zip          # Archive containing stopwords files.
â”‚   â””â”€â”€ MasterDictionary.zip   # Archive containing the master dictionary for NLP tasks.
â”œâ”€â”€ scripts/                   # Helper scripts for processing, analyzing, and predictions.
â”‚   â””â”€â”€ article_scraper_nlp.py # Script for scraping articles and performing NLP tasks.
â”œâ”€â”€ visuals/                   # Visual assets for documentation.
    â””â”€â”€ (e.g., images, flowcharts)
```

## ğŸ“Š Results

<img src="https://github.com/Shuhaib73/Data_Mining_NLP/blob/main/Picture1.png" alt="Generated Image 1" style="max-width: 35%; height: 250px; border: 2px solid #ccc; border-radius: 8px; display: inline-block; margin-right: 10px;">


